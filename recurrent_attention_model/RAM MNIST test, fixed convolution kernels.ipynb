{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import copy  # To make a deepcopy of the mainVQN\n",
    "import os\n",
    "import time\n",
    "\n",
    "from PIL.Image import BICUBIC\n",
    "from torchvision.datasets import MNIST\n",
    "from ram import RecurrentAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "num_classes = 10       # Digits 0-9\n",
    "image_size = 28        # MNIST images are 28x28 b/w images\n",
    "in_channels = 1\n",
    "\n",
    "# Basic training hyperparameters\n",
    "batch_size = 1\n",
    "lr = 0.01\n",
    "grad_clip = 1\n",
    "\n",
    "# Model hyperparameters\n",
    "glimpse_sizes = [5, 7, 10]\n",
    "padding = int((glimpse_sizes[-1] - 1) // 2)\n",
    "padded_img_size = image_size + 2*padding\n",
    "pad_imgs = False                 # We'll prepad to speed things up\n",
    "glimpse_h_size = 128             # Size of the transformed Glimpse representation in the GlimpseNetwork\n",
    "loc_h_size = 128                 # Size of the transformed location representation in the GlimpseNetwork\n",
    "glimpse_network_size = 256       # Size of the GlimpseNetwork output\n",
    "rnn_state_size = 256\n",
    "action_state_size = num_classes  # Classification task\n",
    "num_rnn_layers = 1\n",
    "learn_kernels = False\n",
    "continuous_location = True       # Glimpse locations are represented using pairs of floats in the range of (0, 1)\n",
    "dropout = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mainVQN (that will be predicting the best actions to take)\n",
    "# and the valueVQN (that will be estimating the Q-values for the actions\n",
    "# predicted by the mainVQN)\n",
    "mainVQN = RecurrentAttentionModel(\n",
    "    image_size = image_size, in_channels = in_channels,\n",
    "    glimpse_h_size = glimpse_h_size, loc_h_size = loc_h_size,\n",
    "    glimpse_network_size = glimpse_network_size,\n",
    "    rnn_state_size = rnn_state_size,\n",
    "    action_state_size = action_state_size,\n",
    "    num_rnn_layers = num_rnn_layers, glimpse_sizes = glimpse_sizes,\n",
    "    pad_imgs = pad_imgs, learn_kernels = learn_kernels,\n",
    "    continuous_location = continuous_location\n",
    ")\n",
    "# Deepcopy the mainVQN to get the valueVQN\n",
    "valueVQN = copy.deepcopy(mainVQN)\n",
    "# Set valueVQN's parameters to not require gradients since we'll\n",
    "# be updating them manually rather than through backpropagation\n",
    "for p in valueVQN.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down/load MNIST data\n",
    "mnist_data_loc = os.path.join('data', 'mnist')\n",
    "data_transforms = transforms.Compose([ # Keep things pretty basic for now\n",
    "    # Rotate images a random number of degrees in the range (-deg, deg), keeping the same image size\n",
    "    transforms.RandomRotation(degrees = 65),\n",
    "    # Crop the given PIL Image at a random location\n",
    "    transforms.RandomCrop(size = 24),\n",
    "    # Resize the input PIL Image to the given size\n",
    "    transforms.Resize(image_size, interpolation = BICUBIC),\n",
    "    # Pad images with 0s so the GlimpseSensor won't have to\n",
    "    transforms.Pad(padding = padding),\n",
    "    # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    # to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Training dataset and dataloader\n",
    "mnist_train_dataset = MNIST(\n",
    "    root = mnist_data_loc, train = True, download = True,\n",
    "    transform = data_transforms\n",
    ")\n",
    "train_data = utils.data.DataLoader(\n",
    "    mnist_train_dataset, batch_size = batch_size, shuffle = True,\n",
    ")\n",
    "\n",
    "# Test dataset and dataloader\n",
    "mnist_test_dataset = MNIST(\n",
    "    root = mnist_data_loc, train = False, download = True,\n",
    "    transform = data_transforms\n",
    ")\n",
    "test_data = utils.data.DataLoader(\n",
    "    mnist_test_dataset, batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL training hyperparameters\n",
    "max_ep_len = 30                 # Maximum number of glimpses per episode\n",
    "explore_steps = 25              # Number of initial steps to just explore by using random glimpse locations\n",
    "pretrain_steps = 10000          # Number of steps over which to anneal the Boltzmann temperature\n",
    "num_episodes = len(train_data)  # Go through each example (as a single episode) in the training set once per epoch\n",
    "num_epochs = 10                 # Number of times to go through all of the training examples\n",
    "\n",
    "error_penalty = 0.  # Amount of penalty to apply each time the agent makes an incorrect classification (>= 0.)\n",
    "gamma = 0.99        # Reward discount factor\n",
    "tau = 0.001         # Weight applied to the main RAM's parameters to use when updating the value-predicting RAM's parameters\n",
    "\n",
    "epsilon_start = 1         # Starting and ending probabilities of taking a random action during the initial exploration\n",
    "epsilon_end = 0.1         #   steps. This value is annealed over the course of the initial exploration period\n",
    "boltz_temp_start = 100.   # Starting and ending Boltzmann temperatures used to encourage exploration. This is annealed\n",
    "boltz_temp_end = 1.       #   over the course of training so that by the end, a regular softmax is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience replay buffer\n",
    "class ExperienceReplayBuffer:\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "    def add(self, experience):\n",
    "        if len(self.buffer) + 1 >= self.buffer_size:\n",
    "            self.buffer[0 : len(self.buffer)-self.buffer_size+1] = []\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_sz, trace_ln):\n",
    "        sampled_eps = random.sample(self.buffer, batch_sz)\n",
    "        sampled_traces = []\n",
    "        for ep in sampled_eps:\n",
    "            try:\n",
    "                t_s = np.random.randint(0, len(ep)-trace_ln+1)\n",
    "            except:\n",
    "                print('len(self.buffer) = %d  | len(sampled_eps) = %d' % (len(self.buffer), len(sampled_eps)))\n",
    "                print('len(ep) = %d  | trace_ln = %d' % (len(ep), trace_ln))\n",
    "                print(self.buffer, '\\n\\n\\n')\n",
    "                print(sampled_eps)\n",
    "            t_e = t_s + trace_ln\n",
    "            sampled_traces.append(ep[t_s : t_e])\n",
    "        sampled_traces = np.array(sampled_traces)\n",
    "        return np.reshape(sampled_traces, [batch_sz*trace_ln, 5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
