{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from PIL.Image import BICUBIC\n",
    "from torchvision.datasets import MNIST\n",
    "from ram import RecurrentAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "num_classes = 10       # Digits 0-9\n",
    "image_size = 28        # MNIST images are 28x28 b/w images\n",
    "in_channels = 1\n",
    "\n",
    "# Basic training hyperparameters\n",
    "batch_size = 1\n",
    "lr = 0.01\n",
    "grad_clip = 1\n",
    "\n",
    "# Model hyperparameters\n",
    "glimpse_sizes = [5, 7, 10]\n",
    "padding = int((glimpse_sizes[-1] - 1) // 2)\n",
    "padded_img_size = image_size + 2*padding\n",
    "pad_imgs = False                 # We'll prepad to speed things up\n",
    "glimpse_h_size = 128             # Size of the transformed Glimpse representation in the GlimpseNetwork\n",
    "loc_h_size = 128                 # Size of the transformed location representation in the GlimpseNetwork\n",
    "glimpse_network_size = 256       # Size of the GlimpseNetwork output\n",
    "rnn_state_size = 256\n",
    "action_state_size = num_classes  # Classification task\n",
    "num_rnn_layers = 1\n",
    "learn_kernels = False\n",
    "preserve_out_channels = True     # Doesn't matter in this case, but oh well\n",
    "continuous_location = True       # Glimpse locations are represented using pairs of floats in the range of (0, 1)\n",
    "dropout = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down/load MNIST data\n",
    "mnist_data_loc = os.path.join('data', 'mnist')\n",
    "data_transforms = transforms.Compose([ # Keep things pretty basic for now\n",
    "    # Rotate images a random number of degrees in the range (-deg, deg), keeping the same image size\n",
    "    transforms.RandomRotation(degrees = 65),\n",
    "    # Crop the given PIL Image at a random location\n",
    "    transforms.RandomCrop(size = 24),\n",
    "    # Resize the input PIL Image to the given size\n",
    "    transforms.Resize(image_size, interpolation = BICUBIC),\n",
    "    # Pad images with 0s so the GlimpseSensor won't have to\n",
    "    transforms.Pad(padding = padding),\n",
    "    # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    # to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Training dataset and dataloader\n",
    "mnist_train_dataset = MNIST(\n",
    "    root = mnist_data_loc, train = True, download = True,\n",
    "    transform = data_transforms\n",
    ")\n",
    "train_data = utils.data.DataLoader(\n",
    "    mnist_train_dataset, batch_size = batch_size, shuffle = True,\n",
    ")\n",
    "\n",
    "# Test dataset and dataloader\n",
    "mnist_test_dataset = MNIST(\n",
    "    root = mnist_data_loc, train = False, download = True,\n",
    "    transform = data_transforms\n",
    ")\n",
    "test_data = utils.data.DataLoader(\n",
    "    mnist_test_dataset, batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL training hyperparameters\n",
    "e_start = 1        # Starting and ending probabilities of taking a random action during the initial exploration\n",
    "e_end = 0.1        #  steps. This value is annealed over the course of the initial exploration period\n",
    "temp_start = 100.  # Starting and ending Boltzmann temperatures used to encourage exploration. This is annealed\n",
    "temp_end = 1.      #  over the course of training so that by the end, a regular softmax is used\n",
    "\n",
    "max_ep_len = 30                 # Maximum number of glimpses per episode\n",
    "explore_steps = 10000           # Number of initial steps to just explore by using random glimpse locations\n",
    "temp_anneal_steps = 10000       # Number of steps over which to anneal the Boltzmann temperature\n",
    "num_episodes = len(train_data)  # Go through each example (as a single episode) in the training set once per epoch\n",
    "num_epochs = 10                 # Number of times to go through all of the training examples\n",
    "\n",
    "tau = 0.001         # Weight applied to the main network's parameters to use when updating the target network's parameters\n",
    "gamma = 0.99        # Reward discount factor\n",
    "error_penalty = 0.  # Amount of penalty to apply each time the agent makes an incorrect classification (>= 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
